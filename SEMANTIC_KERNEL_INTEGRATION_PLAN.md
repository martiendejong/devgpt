# Semantic Kernel Integration Plan for DevGPT

## Overview
Integrate Microsoft Semantic Kernel into DevGPT to leverage enterprise-grade orchestration, plugin architecture, and advanced agent capabilities while preserving existing DocumentStore RAG functionality.

---

## Phase 1: Core Infrastructure (3-5 days)

### 1.1 Create New Library: `DevGPT.LLMs.SemanticKernel`
- **Package**: `Microsoft.SemanticKernel` (latest stable)
- **Dependencies**: `DevGPT.LLMs.Client`, `DevGPT.LLMs.Classes`
- **Structure**:
  ```
  DevGPT.LLMs.SemanticKernel/
    ├── Core/
    │   ├── SemanticKernelClientWrapper.cs (implements ILLMClient)
    │   ├── SemanticKernelConfig.cs
    │   └── DevGPTKernelBuilder.cs
    ├── Extensions/
    │   ├── DevGPTSemanticKernelExtensions.cs (ChatHistory <-> DevGPTChatMessage)
    │   └── ToolsContextPlugin.cs (IToolsContext -> SK Plugin adapter)
    ├── Handlers/
    │   └── SemanticKernelStreamHandler.cs
    └── Plugins/
        └── BaseDevGPTPlugin.cs
  ```

### 1.2 Implement `SemanticKernelClientWrapper : ILLMClient`
Key responsibilities:
- Wrap SK `IChatCompletionService`
- Convert `DevGPTChatMessage` ↔ SK `ChatHistory`
- Map `IToolsContext` tools to SK plugins dynamically
- Implement streaming via `IAsyncEnumerable<StreamingChatMessageContent>`
- Extract token usage from SK metadata
- Preserve cost calculation logic

### 1.3 Configuration Mapping
- Extend `SemanticKernelConfig` to match `OpenAIConfig` structure
- Support multiple providers (OpenAI, Azure OpenAI, Ollama, custom)
- Maintain backward compatibility with existing `appsettings.json`

---

## Phase 2: Tool & Plugin System (3-4 days)

### 2.1 Create Document Store Plugins
Convert existing store tools to SK plugins:

**`DocumentStorePlugin`**:
- `ListFiles` (replaces `{store}_list`)
- `ReadFile` (replaces `{store}_read`)
- `SearchRelevant` (replaces `{store}_relevancy`)
- `WriteFile` (replaces `{store}_write`)
- `DeleteFile` (replaces `{store}_delete`)
- `MoveFile` (replaces `{store}_move`)

**`RAGPlugin`**:
- `GetRelevantDocuments` (integrated RAG query)
- `GetDocumentContext` (assemble context with embeddings)

### 2.2 Convert Existing Tool Sets to SK Plugins
- **`GitPlugin`**: git operations (status, diff, commit, etc.)
- **`DotNetPlugin`**: dotnet build, test, publish
- **`NpmPlugin`**: npm install, build, test
- **`BuildPlugin`**: generic build tools
- **`BigQueryPlugin`**: Google BigQuery operations
- **`WebScraperPlugin`**: web page fetching
- **`EmailPlugin`**: email send/receive

### 2.3 Dynamic Tool Registration Adapter
Create `ToolsContextPluginAdapter`:
- Scan `IToolsContext.Tools` collection
- Generate SK `KernelFunction` for each `DevGPTChatTool`
- Register dynamically with kernel
- Preserve existing tool execution signatures

---

## Phase 3: Agent Layer Integration (4-5 days)

### 3.1 Create `SemanticKernelAgent : DevGPTAgent`
Options:
- **Option A (Lightweight)**: Extend `DevGPTAgent`, swap `DocumentGenerator` with SK-backed version
- **Option B (Full SK)**: Use SK's native `ChatCompletionAgent` with custom plugins

Recommended: **Option A** for backward compatibility

### 3.2 Update `DocumentGenerator`
- Add constructor overload accepting `ILLMClient` (SK wrapper)
- Preserve existing RAG logic (`PrepareMessages`)
- Delegate LLM calls to SK kernel
- Maintain `UpdateStoreResponse` typing system

### 3.3 Multi-Agent Orchestration with SK Agents
- Create `SemanticKernelFlowOrchestrator`
- Map `DevGPTFlow` to SK agent group chat patterns
- Support handoff between agents
- Maintain existing flow execution contract

---

## Phase 4: Streaming & Response Handling (2-3 days)

### 4.1 Implement Streaming Bridge
```csharp
public async Task<LLMResponse<string>> GetResponseStream(
    List<DevGPTChatMessage> messages,
    Action<string> onChunkReceived,
    DevGPTChatResponseFormat responseFormat,
    IToolsContext? toolsContext,
    List<ImageData>? images,
    CancellationToken cancel)
{
    var chatHistory = messages.ToSemanticKernelChatHistory();
    var kernel = BuildKernelWithTools(toolsContext);

    var fullResponse = new StringBuilder();
    var tokenUsage = new TokenUsageInfo();

    await foreach (var chunk in kernel.InvokeStreamingAsync<StreamingChatMessageContent>(
        chatHistory,
        cancellationToken: cancel))
    {
        var text = chunk.Content;
        fullResponse.Append(text);
        onChunkReceived?.Invoke(text);

        // Extract token usage from metadata
        if (chunk.Metadata?.ContainsKey("Usage") == true)
            UpdateTokenUsage(tokenUsage, chunk.Metadata["Usage"]);
    }

    return new LLMResponse<string>(fullResponse.ToString(), tokenUsage);
}
```

### 4.2 Token Usage & Cost Tracking
- Extract token counts from SK `FunctionResult.Metadata`
- Preserve existing cost calculation logic
- Aggregate across multi-turn tool interactions

---

## Phase 5: Typed Responses & Schema Support (2-3 days)

### 5.1 Structured Output Integration
SK now supports structured outputs natively. Two approaches:

**Approach 1**: Use SK's `PromptExecutionSettings` with `ResponseFormat`
```csharp
var settings = new OpenAIPromptExecutionSettings
{
    ResponseFormat = typeof(UpdateStoreResponse)
};
var result = await kernel.InvokeAsync<UpdateStoreResponse>(chatHistory, settings);
```

**Approach 2**: Preserve existing `ChatResponse<T>` system
- Continue injecting JSON schema into system prompt
- Parse response using existing `Parser.Parse<T>()`
- Gradual migration to SK native structured outputs

Recommended: **Hybrid** - use SK for new code, maintain compatibility

---

## Phase 6: Advanced SK Features (Optional, 3-5 days)

### 6.1 SK Planners
- Integrate SK `FunctionCallingStepwisePlanner` for autonomous task decomposition
- Replace manual tool loop with SK planner
- Add planning capabilities to agents

### 6.2 SK Memory
- Integrate SK semantic memory for long-term context
- Replace/augment existing `EmbeddingFileStore` with SK connectors
- Support vector DB backends (Postgres pgvector, Qdrant, etc.)

### 6.3 SK Prompt Templates
- Migrate system prompts to SK prompt template format
- Add variable injection and conditional logic
- Support prompt versioning and A/B testing

---

## Phase 7: Testing & Migration (4-5 days)

### 7.1 Unit Tests
- Test `SemanticKernelClientWrapper` against `ILLMClient` contract
- Test plugin conversions (tool parameters, execution)
- Test streaming and token tracking
- Test typed response parsing

### 7.2 Integration Tests
- End-to-end agent execution with SK backend
- Multi-agent flow orchestration
- Document store operations via SK plugins
- Compare outputs with existing OpenAI implementation

### 7.3 Migration Path
- Add feature flag: `UseSemanticKernel` in config
- Support both `OpenAIClientWrapper` and `SemanticKernelClientWrapper`
- Gradual migration per agent/flow
- Deprecation timeline for direct OpenAI wrapper

---

## Phase 8: Documentation & Samples (2-3 days)

### 8.1 Update README
- Add Semantic Kernel section
- Document new configuration options
- Explain plugin system

### 8.2 Create Examples
- Simple SK agent example
- Plugin creation guide
- Multi-agent orchestration with SK
- Custom planner integration

### 8.3 Migration Guide
- Step-by-step from OpenAI wrapper to SK
- Plugin conversion cheat sheet
- Troubleshooting common issues

---

## Detailed File Plan

### New Files to Create:

1. **`DevGPT.LLMs.SemanticKernel.csproj`** - new library project
2. **`SemanticKernelClientWrapper.cs`** - core `ILLMClient` implementation
3. **`SemanticKernelConfig.cs`** - configuration model
4. **`DevGPTSemanticKernelExtensions.cs`** - conversion extensions
5. **`ToolsContextPluginAdapter.cs`** - dynamic tool-to-plugin conversion
6. **`DocumentStorePlugin.cs`** - store operations plugin
7. **`RAGPlugin.cs`** - RAG-specific operations
8. **`GitPlugin.cs`**, **`DotNetPlugin.cs`**, **`NpmPlugin.cs`** - refactored tool sets
9. **`SemanticKernelStreamHandler.cs`** - streaming implementation
10. **`SemanticKernelAgent.cs`** - SK-backed agent (optional)

### Files to Modify:

1. **`AgentFactory.cs`** - add SK agent creation methods
2. **`DocumentGenerator.cs`** - add SK client support
3. **`DevGPT.sln`** - add new project
4. **`appsettings.json`** - add SK configuration section
5. **`README.md`** - document SK integration

### Tests to Create:

1. **`DevGPT.LLMs.SemanticKernel.Tests/`**
   - `SemanticKernelClientWrapperTests.cs`
   - `PluginAdapterTests.cs`
   - `DocumentStorePluginTests.cs`
   - `StreamingTests.cs`
   - `TokenTrackingTests.cs`

---

## Risk Assessment & Mitigation

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| SK API breaking changes | Medium | High | Pin to stable version, abstract SK internals |
| Performance regression | Medium | Medium | Benchmark before/after, optimize hot paths |
| Plugin compatibility | Low | High | Extensive integration tests, gradual rollout |
| Token tracking accuracy | Low | Medium | Cross-validate with OpenAI wrapper |
| Streaming reliability | Low | High | Fallback to non-streaming, comprehensive error handling |

---

## Success Criteria

1. ✅ All existing `ILLMClient` tests pass with SK wrapper
2. ✅ Streaming produces identical outputs to OpenAI wrapper
3. ✅ Token usage accuracy within 1% of direct OpenAI calls
4. ✅ All existing tools converted to SK plugins
5. ✅ Multi-agent flows work with SK orchestration
6. ✅ Performance within 10% of baseline
7. ✅ Zero breaking changes to public APIs
8. ✅ Comprehensive documentation and samples

---

## Timeline Summary

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| 1. Core Infrastructure | 3-5 days | None |
| 2. Tool & Plugin System | 3-4 days | Phase 1 |
| 3. Agent Layer | 4-5 days | Phase 1, 2 |
| 4. Streaming & Responses | 2-3 days | Phase 1 |
| 5. Typed Responses | 2-3 days | Phase 1, 4 |
| 6. Advanced SK Features (Optional) | 3-5 days | Phase 1-5 |
| 7. Testing & Migration | 4-5 days | Phase 1-5 |
| 8. Documentation | 2-3 days | Phase 1-7 |

**Total**: 20-30 days (4-6 weeks) for complete integration
**Minimum Viable**: 12-17 days (2.5-3.5 weeks) without Phase 6

---

## Recommended Approach

**Sprint 1 (Week 1-2)**: Core + Plugins
- Phase 1: Core Infrastructure
- Phase 2: Tool & Plugin System

**Sprint 2 (Week 2-3)**: Integration
- Phase 3: Agent Layer
- Phase 4: Streaming

**Sprint 3 (Week 3-4)**: Polish & Test
- Phase 5: Typed Responses
- Phase 7: Testing & Migration

**Sprint 4 (Week 4+)**: Advanced (Optional)
- Phase 6: SK Planners, Memory
- Phase 8: Documentation

This plan maintains full backward compatibility while enabling gradual migration to Semantic Kernel's advanced features.
